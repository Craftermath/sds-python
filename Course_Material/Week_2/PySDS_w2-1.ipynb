{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PySDS Week 2 Lecture 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key data structures: \n",
    "- Numpy Array\n",
    "- Series\n",
    "- DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Array \n",
    "\n",
    "The numpy array is the basis of the series and data frame objects. It is very efficient. Unlike a list, the objects in an array are of the same type. This allows for considerably faster computation. Here it is worth pointing out that much of python is actually a wrapper for ```c``` code. C is a pervasive, extremely efficient language. That said, it is often cumbersome to use and does not provide anywhere near the level of abstraction of python. Numpy uses C more directly than python lists do.  \n",
    "\n",
    "We tend not to use the numpy array directly although it can be useful for a number of tricks, as we will show later. One in particular is for generating multiple columns of random numbers. However, for the most part we only interface numpy through PANDAS and not directly. \n",
    "\n",
    "A numpy array is designed to implement matrix algebra, something useful in a variety of circumstances. For example, we can characterise a **social network** as a matrix and then use that matrix to learn things about the network. \n",
    "\n",
    "Before we get there, however, let's introduce the simple unidimensional array, sometimes called a **vector**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "x = [1,2,3]\n",
    "\n",
    "npx = np.array([1,2,3])\n",
    "\n",
    "print(x,npx)\n",
    "\n",
    "print(x[0],npx[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy array can be unidimensional (i.e. just like a single list) or multidimentional. When it is unidimensional it is sometimes referred to as a vector. This is not quite appropriate according to the mathematicians, but it seems to be popular in computer languages. \n",
    "\n",
    "A two dimensional array is referred to as a matrix. So if we have a vector of friendship nominations that means we have a one dimensional array representing friendships from that person to the other people. \n",
    "\n",
    "If we have four friends, Alice, Bob, Charlie and Diane, they each have a vector referring to whether they are friends with each other. Let's keep each one of these in order of A,B,C,D. So for Alice, if she is only friends with Diane, her vector would look like: \n",
    "```\n",
    "Alice = np.array([0,0,0,1])\n",
    "```\n",
    "Whereas Diane might consider herseff friends with everyone. So hers looks like: \n",
    "```\n",
    "Diane = np.array([1,1,1,0])\n",
    "```\n",
    "Notice that zero at the end? That's because Diane can't be friends with herself. When you stitch these one dimensional arrays together, you can get a matrix representing the network of friendships, like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alice = np.array([0,0,0,1])\n",
    "Bob = np.array([1,0,0,1])\n",
    "Charlie = np.array([0,1,0,1])\n",
    "Diane = np.array([1,1,1,0])\n",
    "\n",
    "friendshipMatrix = np.array([Alice,Bob,Charlie,Diane])\n",
    "\n",
    "print(friendshipMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a couple things about the output. First about the structure and second about the semantics. \n",
    "\n",
    "1. The structure: \n",
    " - It's not very clear who is who in this matrix. We know that it goes Alice, Bob, Charlie, Diane so we can follow along. But that gets particularly difficult when we have many rows and columns we have to manage. Part of the reason for using PANDAS is that where an array is simplified, a PANDAS DataFrame allows us to have row and column labels, as well as indexing by that label. We will show this in a minute. \n",
    "\n",
    "2. The semantics:\n",
    " - Notice that we said this was a network of friendships. Well, aren't friends supposed to be symmetric? Bob said Alice was his friend, but Alice did not say Bob was her friend. Drama! What if we had a way to determine whether a friendship is reciprocated? This is where ```numpy``` shines as a means of doing **linear algebra**. \n",
    " - As we go through this example, it will be clear that not only is matrix algebra useful, but that it can be hard to follow without having labels on the rows and columns. So first let's do it, and then we will move over to the nicer data structures with labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to determine if a friendship is reciprocated\n",
    "\n",
    "1. To do this we would first flip the matrix around. Right now we have it so that we have rows of 'from' and columns of 'to'. So it is a row of friendship nominations from Alice to Bob, Charlie and Diane. By **transposing**  we can turn this on its head so that it 'to' in the columns and 'from' in the rows.\n",
    " - ```newMat = oldMat.transpose()```\n",
    " - $ \\mathbf{A}^T$\n",
    "2. Then we can multiply each cell by its corresponding cell in the transposed matrix. If the friendship is unreciprocated, then the result will be $1 * 0$ which is $0$. If it is reciprocated, then it will be a $1$. This will be a matrix of reciprocated friendships. \n",
    " - ```recipMat = oldMat * newMat```\n",
    " - $ \\mathbf{A}_r = \\mathbf{A} * \\mathbf{A}^T $\n",
    "3. Finally, let's remove the reciprocated friendships from the original matrix. What we have left over are the unreciprocated friendships. \n",
    " - ```unrecip = mat - recipMat```\n",
    " - $ \\mathbf{A}_u = \\mathbf{A} - \\mathbf{A}_r $\n",
    "\n",
    "See below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix from four vectors\n",
    "Alice = np.array([0,0,0,1])\n",
    "Bob = np.array([1,0,0,1])\n",
    "Charlie = np.array([0,1,0,1])\n",
    "Diane = np.array([1,1,1,0])\n",
    "\n",
    "friendMat = np.array([Alice,Bob,Charlie,Diane])\n",
    "print(\"The friendship matrix:\")\n",
    "print(friendMat,'\\n')\n",
    "\n",
    "# Get the transpose of that matrix\n",
    "tMat = friendMat.T\n",
    "\n",
    "print(\"The transposed matrix:\")\n",
    "print(tMat,'\\n')\n",
    "\n",
    "# Get the reciporcated friendships\n",
    "recipMat = tMat * friendMat \n",
    "\n",
    "print(\"The reciprocated friendships\")\n",
    "print(recipMat,'\\n')\n",
    "\n",
    "# Get the unreciprocated friendships\n",
    "unrecipMat = friendMat - recipMat\n",
    "\n",
    "print(\"The unreciprocated friendships\")\n",
    "print(unrecipMat,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The SERIES data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Series data structure is very much akin to a vector. It is unidimensional and it classifies everything in the structure as a common type. If it is all integers, the Series will be of type integer. If it is a mix of integers and strings, it will be of type 'object', which is more generic. \n",
    "\n",
    "A series has an index which can be automatically created. The indices do not have to be unique, but if they are not, then the coder runs the risk of accidentally indexing the wrong element. We will show how to keep indices tidy later on. \n",
    "\n",
    "Let's import the series below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "# Creates a single element series (not four empty rows)\n",
    "ser1 = Series(4)\n",
    "\n",
    "print(ser1)\n",
    "\n",
    "# Creates a series with four of the same elements:\n",
    "\n",
    "ser2 = Series([1]*4)\n",
    "\n",
    "print(ser2)\n",
    "\n",
    "# Creates a series with a range of numbers: \n",
    "# Remember with range when you have three arguments it is:\n",
    "# range(<start>,<exclusive stop>,<step>)\n",
    "\n",
    "ser3 = Series(range(1,8,2))\n",
    "print(ser3)\n",
    "\n",
    "# Create a series with a string. Notice that since it is non-numeric, it's just classed as 'object'\n",
    "\n",
    "ser4 = Series([\"Alice\",\"Bob\",\"Charlie\",\"Diane\"])\n",
    "print(ser4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on a series. \n",
    "\n",
    "We can operate on every element in a series directly. Whereas with a list if we type ```list1 * 2``` the result will be the list, only doubled. But if we do it for a series, we will multiple _every element_ ```* 2```. See below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "# This here is a 'function' - we call this function with an\n",
    "# argument. This means we send it input (ListToDouble) and\n",
    "# and it returns output.\n",
    "\n",
    "def doubleUpDemo(listToDouble):\n",
    "    print(\"Here's a list * 2\")\n",
    "    print(listToDouble*2)\n",
    "    print() \n",
    "    \n",
    "    ser1 = Series(listToDouble)\n",
    "    print(\"Here's a series * 2\")\n",
    "    print(ser1 * 2)\n",
    "    print()\n",
    "    return \n",
    "\n",
    "# First we send a list of integers to the function\n",
    "doubleUpDemo([1,2,3,4])\n",
    "\n",
    "# Next we send a list of strings\n",
    "doubleUpDemo([\"a\",\"b\",\"c\",\"d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we used strings, the cells doubled the string inside the list. This is because the ```*``` operator is **overloaded** which means that it refers to multiple potential operations depending on the context. The ```+``` symbol is also overloaded as we already know. It can mean both plus and concatenate. If we tried that with an operator that is not overloaded, such as exponent, then we would have got an error. See below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "print(\"Here's a series of numbers to the second power\")\n",
    "\n",
    "ser1 = Series([1,2,3,4])\n",
    "print(ser1 ** 2)\n",
    "print()\n",
    "\n",
    "print(\"Here's a series of strings to the second power\")\n",
    "\n",
    "ser2 = Series([\"a\",\"b\",\"c\",\"d\"])\n",
    "print(ser2 ** 2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series and indices \n",
    "\n",
    "Every series has an index for each of the elements in the series. The index itself is available through ```<seriesName>.index```. The index is mutable, so you can either create new names for your index when you create your series or do it later on. You can also reindex a series, which is important if you're concatenating two series. \n",
    "\n",
    "A series is **ordered** so we can index every element by its position in addition to indexing it by the index name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series \n",
    "\n",
    "ser1 = Series([\"a\",\"b\",\"c\",\"d\"], index = [\"alpha\",\"bravo\",\"charlie\",\"delta\"])\n",
    "print(ser1,\"\\n\")\n",
    "print(\"Here is the first element:\",ser1[0],\"\\n\")\n",
    "print(ser1,\"\\n\")\n",
    "print(\"Here is the element from index 'alpha':\",ser1[\"alpha\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just because it is ordered and you, in theory, can index it by position, _you really shouldn't_. Just watch what happens when we give the index numerical values in the wrong order. When we try to index element 0 we get 'c' and not 'a' as we got above. Instead, you should always index either by name if you need to access the values in a series, or simply in order.\n",
    "\n",
    "That being said, positional numbers are still really useful for slicing and will always work as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1.index = [1,4,0,2]\n",
    "print(ser1)\n",
    "\n",
    "print(\"By position?\")\n",
    "print(ser1[0],\"\\n\")\n",
    "\n",
    "print(\"Slicing up to the third element.\")\n",
    "print(ser1[:2],\"\\n\")\n",
    "\n",
    "print(\"Slicing from third element onwards.\")\n",
    "print(ser1[2:],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to create a series\n",
    "\n",
    "We already saw how to create a series from a list as well as an index from a list. If you have a dictionary, you can also turn it into a series. It will keep the key as the index and the value as the value in the cell. See below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "# You can also create a series with an index in one go using a dictionary. \n",
    "\n",
    "dict1 = {\"alpha\":\"a\",\"bravo\":\"b\",\"delta\":\"d\",\"epsilon\":\"e\"}\n",
    "ser1 = Series(dict1)\n",
    "\n",
    "print(ser1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your series has a **misalignment** between the length of the collection of values and the length of the index, pandas will try to infer what to do. Typically this involves throwing an error if the index and the series are not of the same length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "values1 = [1,3,5]\n",
    "index1 = [\"Apples\",\"Oranges\",\"Bananas\",\"kiwis\",\"durian\"]\n",
    "\n",
    "ser1 = Series(values1,index=index1) \n",
    "print(ser1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering a series\n",
    "\n",
    "There are many ways to filter a series. Two featured here involve **slicing** and **Boolean logic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing \n",
    "\n",
    "Just like how a list can be sliced, we can similarly slice a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "ser1 = Series([\"a\",\"b\",\"c\",\"d\"])\n",
    "\n",
    "ser1.index = [1,4,0,2]\n",
    "print(ser1,\"\\n\")\n",
    "\n",
    "print(\"By position?\")\n",
    "print(ser1[0],\"\\n\")\n",
    "\n",
    "print(\"Slicing up to the third element.\")\n",
    "print(ser1[:2],\"\\n\")\n",
    "\n",
    "print(\"Slicing from third element onwards.\")\n",
    "print(ser1[2:],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Logic\n",
    "If you recall, Boolean logic allows you to evaluate the logical truth condition of a statement. So if ```x = 4``` and ```y = 4``` then ```x == y``` will be true. With a series, instead of returning whether _the series_ is true or false, it evaluates each cell and returns a new series of True and False values that satisfy that condition. So if we have a series:\n",
    "~~~py \n",
    "ser1 = [1,2,3,4,5]\n",
    "~~~\n",
    "Then asking:\n",
    "~~~py\n",
    "ser1 > 3\n",
    "~~~\n",
    "will return a series with only those values greater than 3. See the example below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "ser1 = Series([\"a\",\"b\",\"c\",\"d\"])\n",
    "ser2 = Series([1,3,5,7,9,11])\n",
    "\n",
    "# We can filter a series in lots of different ways. \n",
    "\n",
    "# Every time you evaluate a series by boolean logic it returns a series of that length true / false\n",
    "print(ser1 > \"c\")\n",
    "print()\n",
    "\n",
    "print(ser2 > 5)\n",
    "print() \n",
    "\n",
    "# You can then apply this to your original series to filter out the false entries. \n",
    "ser2q = ser2 > 5\n",
    "print(ser2)\n",
    "print()\n",
    "print(ser2q)\n",
    "print(\"\\nThe new slimmer series\\n\")\n",
    "print(ser2[ser2q])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing and filtering is especially useful if you have some missing data and you want to delete the cases \"listwise\", meaning exclude a row. So instead of using a boolean, you would use the function:\n",
    "\n",
    "~~~python \n",
    "series.notnull() \n",
    "~~~\n",
    "\n",
    "which will return true for all the non-null values. You can also use the opposite function: \n",
    "\n",
    "~~~python \n",
    "series.isnull() \n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser3 = Series([1,4,7,None,8,9])\n",
    "print(ser3)\n",
    "\n",
    "print(ser3.isnull())\n",
    "print()\n",
    "\n",
    "print(ser3[ser3.notnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Series Operations \n",
    "\n",
    "There are a number of operations you can do on a series. You can see the lot of them by typing: \n",
    "~~~python\n",
    "dir(Series)\n",
    "~~~\n",
    "\n",
    "We are here focusing on a handful of these for data processing: \n",
    "- value_counts()\n",
    "- unique() \n",
    "- sort() and reindex() \n",
    "\n",
    "### Value Counts\n",
    "\n",
    "```value_counts()``` returns a new series where the earlier values are now indices and the values are the counts of that new index. So if you have a Series with the following numbers:\n",
    "\n",
    "~~~python\n",
    "ser1 = [1,1,7,7,7,33,1,6,33] \n",
    "~~~\n",
    "\n",
    "Then you have 3 of the number 1, 4 of the number 7, 2 of the number 33 and one 6. \n",
    "\n",
    "To see this summarised, type \n",
    "\n",
    "~~~python\n",
    "print (ser1.value_counts()) \n",
    "~~~\n",
    "\n",
    "As ```value_counts()``` returns the new series, we can print it directly. See below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series \n",
    "\n",
    "ser1 = Series([1,1,7,7,7,33,1,6,33])\n",
    "\n",
    "print(ser1,\"\\n\")\n",
    "print(ser1.value_counts(),\"\\n\")\n",
    "\n",
    "# Since a string is a list of charcters this is \n",
    "#also a quick way to get a count of characters in a string. \n",
    "\n",
    "ser2 = Series(list(\"the quick brown fox jumps over the lazy dog\"))\n",
    "print(ser2,\"\\n\")\n",
    "print(ser2.value_counts(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check unique - notice that there's 27 when qbf should have 26 letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the previous example, the quick brown fox... was turned into a series that descended in order from the most frequent to the least frequent. \n",
    "1. What if we want to have it sorted alphanumerically? \n",
    "2. What if we only want counts of valid alphanumeric characters and not spaces? \n",
    "\n",
    "For the first one we can use ```sort_index()``` to resort the numbers by index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "ser1 = Series(list(\"the quick brown fox jumps over the lazy dog\"))\n",
    "ser1 = ser1[ ser1.map(lambda x: x.isalpha()) ]\n",
    "ser1\n",
    "# # print(ser1,\"\\n\")\n",
    "\n",
    "# # print(ser1.value_counts().sort_index())\n",
    "\n",
    "\n",
    "# my_valuable_values = filter(lambda x: x != \"-\", my_values)\n",
    "# print(ser1[ser1.isalpha()].value_counts())\n",
    "# # print(ser5.value_counts().sort_index())\n",
    "# # # What's the 8 at the top mean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use value counts to plot a summary of data as well. \n",
    "\n",
    "ser5.value_counts().sort_index(ascending=False).plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DataFrame data structure\n",
    "\n",
    "DataFrames can be thought of as aggregates of series. They are tabular data structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One dimensional data frame with no indices or column labels \n",
    "df1 = DataFrame([1,2,3,4,5])\n",
    "print(df1,\"\\n\")\n",
    "\n",
    "# Two dimensional data frame with no indices or column labels. \n",
    "# Note each 'inner list' in the list is treated as a row. this is why they will come out horizontal.\n",
    "df2 = DataFrame([[1,2,3,4,5],[2,5,10,17,26]])\n",
    "print(df2,\"\\n\")\n",
    "\n",
    "# Here we can see a data frame of rows\n",
    "# Notice how PANDAS handles the missing value\n",
    "df3 = DataFrame([[1,2],[2,5],[3,10],[NaN,4],[5,26]])\n",
    "print(df3,\"\\n\")\n",
    "\n",
    "# Let's replace the index for this data frame\n",
    "df3.index = [\"first\",\"second\",\"third\",\"fourth\",\"fifth\"]\n",
    "print(df3,\"\\n\")\n",
    "\n",
    "# Let's replace the column labels.\n",
    "df3.columns = [\"number\",\"sq_plus_1\"]\n",
    "print(df3,\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.sort_values(\"number\",ascending=True,inplace=True)\n",
    "\n",
    "print(df3)\n",
    "\n",
    "sortedSQplus1 = df3.sort_values(\"sq_plus_1\",ascending=False)\n",
    "\n",
    "print(sortedSQplus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Data in a Data Frame \n",
    "\n",
    "df_pol = DataFrame.from_csv(\"WD18_PolCandidates.csv\")\n",
    "df_pol.head(3)\n",
    "\n",
    "# Basic - look what happened! \n",
    "# Name is in its own row, the names are now indices.\n",
    "# We want to tell the parser that we want to keep names not as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This should work just fine.\n",
    "df_pol = DataFrame.from_csv(\"WD18_PolCandidates.csv\",index_col=None)\n",
    "# df.head() just prints the first n rows (5 by default)\n",
    "df_pol.head()\n",
    "# Okay, that's much better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pol[(df_pol[\"party\"] == \"Labour Party\") | (df_pol[\"constituency\"] == \"Aberavon\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people tweet by party? \n",
    "# What is the ratio of people who tweet by party? \n",
    "# Report on only those parties with more than 10 people running for office.  \n",
    "\n",
    "# Series 1. How many pepople per party. \n",
    "partyCount = df_pol[\"party\"].value_counts()\n",
    "print(partyCount.head(10))\n",
    "# print()\n",
    "\n",
    "# Series 2. How many people per party have a twitter account\n",
    "haveTwitter = df_pol[\"twitter_username\"].notnull()\n",
    "# print(haveTwitter)\n",
    "partyCountWithTwitter = df_pol[haveTwitter][\"party\"].value_counts()\n",
    "# print(haveTwitter.head(5))\n",
    "# thingsToDisplay = \"party\"\n",
    "\n",
    "# thingsToDisplay2 = [\"party\",\"gender\",\"name\"]\n",
    "\n",
    "\n",
    "# print(df_pol[haveTwitter][thingsToDisplay].value_counts())\n",
    "display(partyCountWithTwitter)\n",
    "# print(partyCountWithTwitter.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame with these two series together\n",
    "# Notice that .T means transpose. This is the simplest way to swap rows and columns.\n",
    "# newarray = list(zip(list(partyCount),list(partyCountWithTwitter)))\n",
    "# print(newarray)\n",
    "\n",
    "# l1 = [1,2,3,4]\n",
    "# l2 = [5,6,7,8]\n",
    "# l3 = zip(l1,l2)\n",
    "# print(list(l3))\n",
    "df_parties = DataFrame([partyCount,partyCountWithTwitter],index=[\"Party Count\",\"Have Twitter\"])\n",
    "df_parties\n",
    "df_parties.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We want to transpose! \n",
    "\n",
    "Transposition in linear algebra is taking the rows and making them the columns (and vice versa)\n",
    "\n",
    "so: \n",
    "~~~\n",
    "a b c d\n",
    "e f g h\n",
    "~~~\n",
    "becomes:\n",
    "~~~\n",
    "a e\n",
    "b f\n",
    "c g\n",
    "d h\n",
    "~~~\n",
    "\n",
    "To do this in a DataFrame we would just add .T at the end. \n",
    "\n",
    "print(DataFrame.T) will print a transposed DataFrame\n",
    "\n",
    "DataFrame = DataFrame.T will make the dataframe permanently transposed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parties = df_parties.T\n",
    "print(df_parties.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a new variable that is the result of two other variables. \n",
    "df_parties[\"proportion\"] =  df_parties[\"Have Twitter\"] / df_parties[\"Party Count\"]\n",
    "\n",
    "df_parties.sort_values(\"proportion\",inplace=True,ascending=True)\n",
    "\n",
    "# We could just print it, but it looks nicer to use the HTML. \n",
    "# Compare: \n",
    "\n",
    "display(df_parties[df_parties[\"Party Count\"] >= 10])\n",
    "\n",
    "# pd.options.display.float_format = '{}'.format\n",
    "# You can use this code to change the display format per table. \n",
    "# Unfortunately, it doesn't work per column. You will have to seek elsewhere for that.\n",
    "# pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# display(df_parties[df_parties[\"Party Count\"] >= 10])\n",
    "\n",
    "# for i in df_parties.index:\n",
    "#     if i in [\"National Front\", \"British National Party\"]:\n",
    "#         display(df_parties.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about counts of a categorical, say, the percent of candidates who were women? \n",
    "# There are lots of ways to do this. I'm going to use a 'map' to map the gender on to a binary\n",
    "\n",
    "# What's the gender column called? \n",
    "print(df_pol.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, it's \"gender\". \n",
    "df_pol[\"gender\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uh oh, it seems that the gender was entered in a number of ways.\n",
    "# What's up with Female there twice? \n",
    "# Let's check\n",
    "print(df_pol[\"gender\"].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-ha! one has \"Female \" and one has \"Female\"\n",
    "# Let's turn this into a binary variable \n",
    "mapper = {\n",
    "    \"male\":0,\n",
    "    \"Male\":0,\n",
    "    \"Man (sex)\":0,\n",
    "    \"female\":1,\n",
    "    \"Female\":1,\n",
    "    \"Female \":1\n",
    "}\n",
    "\n",
    "df_pol[\"bgender\"] = df_pol[\"gender\"].map(mapper)\n",
    "# male = df_pol[\"gender\" == \"\"]\n",
    "# partyCountWithTwitter = df_pol[haveTwitter][\"party\"].value_counts()\n",
    "df_pol[\"bgender\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so we can see that 1035 were women and 2932 were men, 4 were undefined in the data.\n",
    "# Are some parties more gender balanced than others?\n",
    "\n",
    "# First lets 'group' the data\n",
    "polGroup = df_pol.groupby(\"party\")\n",
    "\n",
    "# groupby creates a representation of the same data, not new data. \n",
    "# We can use this representation to create aggregates. \n",
    "# The [:10] just means give me the first ten. \n",
    "print(polGroup[\"bgender\"].mean())\n",
    "\n",
    "# Ok, so this looks coherent. Why don't we append this to our parties dataframe?\n",
    "# That way we can sort in lots of ways, create new varibles for the data frame and more. \n",
    "df_parties[\"gender_ratio\"] = polGroup[\"bgender\"].mean()\n",
    "\n",
    "# This will display the whole table sorted by Gender Ratio:\n",
    "display(df_parties[df_parties[\"Party Count\"] > 10].sort_values(\"gender_ratio\",ascending=False))\n",
    "\n",
    "# Notice in this one, we are only going to sort and display the gender_ratio series. \n",
    "# Do you understand the difference between this code and the code above? \n",
    "display(df_parties[df_parties[\"Party Count\"] > 10][\"gender_ratio\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = \"Percent of Female Candidates by Party (UK 2015 General Election)\"\n",
    "df_parties[df_parties[\"Party Count\"] > 20][\"gender_ratio\"].sort_values(ascending=True).plot(kind=\"barh\",title=plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Optional note for LaTeX users! ####\n",
    "#\n",
    "# We can format these things for LaTeX as well. \n",
    "# Remember the last query we did - just add .to_latex() at the end\n",
    "print(df_parties[df_parties[\"Party Count\"] > 10].sort_values(\"gender_ratio\",ascending=False).to_latex())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types for input / output\n",
    "\n",
    "As a prelude to next week, I'm now introducing a number of different file formats. We will look at these next week, how to get them into and out of Python. \n",
    "\n",
    "- json\n",
    "- xml\n",
    "- sql\n",
    "- csv\n",
    "- Mircosoft Excel (xls and xlsx)\n",
    "- serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON (JavaScript Object Notation)\n",
    "\n",
    "JavaScript Object Notation is a very lightweight format for downloading and storing data from the web. Many APIs use JSON for their file interchange. Considered in terms of python, it is basically just a series of unicode lists and dictionaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML (eXtensible Markup Language) \n",
    "\n",
    "XML is a language for marking up data. Like other 'ML's such as as HTML, there is a header and a body. The header defines many things about the data, and then the body uses tags to signify the data and some properties about it. XML is very verbose as every piece of data is tagged in some way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL (Structured Query Language)\n",
    "\n",
    "SQL is the standard language for querying relational databases (where data is stored in linked tables). Later, we will look at a little bit of data in an SQLite database. That is a data structure that is useful for manging large amounts of data, although more of this will be covered in the Big Data Analytics class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV (Comma Separated Values)\n",
    "\n",
    "Comma-separated values are a traditional way to encode data. It works very simply by using return characters to denote rows and the commas to denote columns. It is possible to read data into Python as a CSV the hard way, but by using the _csv_ package it is possible to import a lot of data programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization - Pickling your data\n",
    "\n",
    "In most langauges there's a way to take a data structure as is and simply write it to a file so that when the file is read it will load the data right up the way it started. Next week we will be pickling and unpickling files. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
