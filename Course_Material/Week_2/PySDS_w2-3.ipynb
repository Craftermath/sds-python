{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 02 Day 03: Data formatting, SQL and more text processing\n",
    "=================\n",
    "\n",
    "Today we will be looking at some further data formatting. We will also be introducing SQL or Structured Query Language. \n",
    "\n",
    "Learning goals: \n",
    "- Understand the use of sql through sqlite. \n",
    "- Making use of Map / Apply / Lambda. \n",
    "- Parsing Dates \n",
    "- Building further regular expressions. \n",
    "\n",
    "We will be using some old data related to the 2016 UK election, but it's useful data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "%pylab inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sql databases\n",
    "\n",
    "SQL stands for Structured Query Language. It is a way to store data in relational tables. This is to say tables that follow the row / column format. Each 'database' can store multiple tables. \n",
    "\n",
    "There has been a movement in recent years away from relational databases towards newer forms of data stores, such as GraphDB and MongoDB, as part of the 'noSQL' paradigm. First, that's silly. Seccond, it's a little presumptuous to assume that other data stores can do the trick better. \n",
    "- MongoDB is a store for json-like objects. It's fast, simple and not so powerful except for queuing systems. \n",
    "- Neo4j is a 'graphdb' that stores entries as nodes and edges. It's hard to wrap your head around, but it does make some form of querying relatively straightforward that would otherwise not be the case. \n",
    "\n",
    "Having worked with Mongo, Neo4j and SQL, I can confidently say that SQL has a very prominent place in data stores. Lately, a number of domains have started to return to SQL databases. This is because while the data can be stored in other more flexible formats, ofte formats that mimic the data in other contexts, they are not so amenable to post-processing. \n",
    "\n",
    "Tables in SQL can be **indexed** or not. When they are indexed, using a 'key' it is easier to query and search for data. Keys keep tables organized but are not necessary. A 'primary key' is an index where each entry is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL is structured query language, but not a specific database type. Most SQL is interoperable, but some is specific to the type of database. There are also SQL flavours that are used in APIs but restrict certain kinds of queries. For a while Facebook had FQL which allowed developers to query for data on select tables. This has been deprecated in favour of a graph database structure. Some example databases are:\n",
    "- ```Oracle```. The version in use in many industries. \n",
    "- ```MySQL```. An open source SQL implementation in use in a lot of server applications. It is the M in a 'LAMP stack', which stands for Linux, Apache, MySQL and PHP, which for many was the building block of dynamic webpages. It is being slowly replaced by NodeJS variants such as React, but is still a common way to build and serve dynamic content. \n",
    "- ```PostGRES```. A version that's often used in academia and some other environments. It can be a bit more tricky to set up than MySQL. \n",
    "- ```SQLite```. The only one of these flavours that isn't designed to be interacted with via a server. SQLite databases exist all over your computer, particularly on a mac. This is because you can just read and write to a SQLite database as if it were a file. \n",
    "\n",
    "We can use SQLite through a number of modules. Two popular ones in python are ```sqlalchemy``` and ```sqlite3```. The former is a little more 'pythonic' in that you can interface with the database through objects and methods. SQLite3 is a little more of a wrapper around direct SQL commands. We will use SQLite3 because it is less abstract as well as allowing you to see SQL commands directly. Below we will see how to open and view details about a database. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as lite\n",
    "con = lite.connect('example.db')\n",
    "\n",
    "cursor = con.cursor()\n",
    "cursor.execute('''\n",
    "    CREATE TABLE if not exists users(id INTEGER PRIMARY KEY, name TEXT,\n",
    "                       phone TEXT, email TEXT unique)\n",
    "''')\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " query To use SQL in \n",
    "\n",
    "\n",
    "\n",
    "Below is the code used to take data from an SQL database (in this case sqlite) and create the tables required for PANDAS. As we can see, it is a very simple process to read from a table. We first write a command in SQL and then send that command to a connection. \n",
    "\n",
    "We will not be teaching SQL per se, but it is worth introducing. I will here discuss sqlite as it is especially handy. This is because unlike MySQL or PostGres you do not need to run a server. SQLite databases are local files. In many cases sqlite is just as fast as other databases. See the course Big Data Analysis for more examples of how to work with databases. \n",
    "\n",
    "If you just want to pipe SQL into a data frame, here are some examples. In general the syntax is: \n",
    "\n",
    "~~~\n",
    "DATAFRAME = pd.read_sql(SQL_COMMAND,sqlite3.connect(DATABASE_FILE)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>595484506439684096</td>\n",
       "      <td>376399949</td>\n",
       "      <td>PlaidDC_CS</td>\n",
       "      <td>2015-05-05 07:05:44.000000</td>\n",
       "      <td>RT @JamesLuchte: Discovering #Plaid #Cymru, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>595577717980037122</td>\n",
       "      <td>80021045</td>\n",
       "      <td>timfarron</td>\n",
       "      <td>2015-05-05 13:16:07.000000</td>\n",
       "      <td>@BrynKewley @nick_clegg @EdwardDaveyMP @LibDem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>595712363963281410</td>\n",
       "      <td>76969741</td>\n",
       "      <td>carlquilliam</td>\n",
       "      <td>2015-05-05 22:11:10.000000</td>\n",
       "      <td>RT @johnestevens: Ukip suspends candidate from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>595619170773028867</td>\n",
       "      <td>19451651</td>\n",
       "      <td>annesnelgrove</td>\n",
       "      <td>2015-05-05 16:00:51.000000</td>\n",
       "      <td>RT @edballsmp: Huge turnout and big momentum i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595710436516958208</td>\n",
       "      <td>27101173</td>\n",
       "      <td>SteveUncles</td>\n",
       "      <td>2015-05-05 22:03:30.000000</td>\n",
       "      <td>With Labour &amp;amp; the SNP in Government, the a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id    user_id       username                        date  \\\n",
       "0  595484506439684096  376399949     PlaidDC_CS  2015-05-05 07:05:44.000000   \n",
       "1  595577717980037122   80021045      timfarron  2015-05-05 13:16:07.000000   \n",
       "2  595712363963281410   76969741   carlquilliam  2015-05-05 22:11:10.000000   \n",
       "3  595619170773028867   19451651  annesnelgrove  2015-05-05 16:00:51.000000   \n",
       "4  595710436516958208   27101173    SteveUncles  2015-05-05 22:03:30.000000   \n",
       "\n",
       "                                                text  \n",
       "0  RT @JamesLuchte: Discovering #Plaid #Cymru, th...  \n",
       "1  @BrynKewley @nick_clegg @EdwardDaveyMP @LibDem...  \n",
       "2  RT @johnestevens: Ukip suspends candidate from...  \n",
       "3  RT @edballsmp: Huge turnout and big momentum i...  \n",
       "4  With Labour &amp; the SNP in Government, the a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>count(username)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOWnotWHO</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>johnnymercer81</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaughan_Wms</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UKIPbevand7</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>james4suffolk</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username  count(username)\n",
       "0       HOWnotWHO              613\n",
       "1  johnnymercer81              352\n",
       "2     Vaughan_Wms              319\n",
       "3     UKIPbevand7              314\n",
       "4   james4suffolk              301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note that youcan view the whole table with SQLite browser: http://sqlitebrowser.org\n",
    "import sqlite3\n",
    "\n",
    "df = pd.read_sql(\"select * from roottweets\",sqlite3.connect(\"may5-6withreplies.db\"))\n",
    "display(df.head())\n",
    "\n",
    "df2 = pd.read_sql(\"select username, count(username) from roottweets group by( username) order by count(username) DESC\",sqlite3.connect(\"may5-6withreplies.db\"))\n",
    "display(df2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates and the datetime module \n",
    "\n",
    "Datetime can be a real nuisance when the date times are stored in a number of different ways. We will deal with one way contained within the tweets from the root tweets. These are stored as strings. Querying the root tweets we can see how they are stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 2015-05-05 07:05:44.000000\n"
     ]
    }
   ],
   "source": [
    "print(   type(df[\"date\"][0]),    df[\"date\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that it is a string, when we really want a date. So we can do this the easy way and the hard way. The easy way is to tell PANDAS to simply convert it and take our chances. We shall do that. Then I shall show you the hard way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hard way is not to use PANDAS but the built-in date time module. Here we can specify using escape codes the different ways that a date is supposed to be formatted. In this case:\n",
    "\n",
    "~~~\n",
    "tweetdate = \"2015-05-05 07:05:44.000\"\n",
    "~~~\n",
    "\n",
    "Can be read as\n",
    "\n",
    "~~~\n",
    "YEAR-MM-DD HH:MM:SS.FFF\n",
    "~~~\n",
    "\n",
    "And we can then build a datetime parser for this in the following way: \n",
    "\n",
    "~~~\n",
    "tweetdateobject = datetime.strptime(tweetdate, '%Y-%m-%d %H:%M:%S.%f')\n",
    "~~~\n",
    "\n",
    "Notice the %Y and %m symbols. These refer to four digit year and month. See page 292 for an example of more of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'> 2015-05-05 07:05:44\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "tweetdate = \"2015-05-05 07:05:44.000\"\n",
    "\n",
    "tweetdateobject = datetime.strptime(tweetdate, '%Y-%m-%d %H:%M:%S.%f')\n",
    "print(type(tweetdateobject),tweetdateobject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method date of datetime.datetime object at 0x10d53b490>\n",
      "5\n",
      "<class 'datetime.time'>\n"
     ]
    }
   ],
   "source": [
    "tdo = tweetdateobject\n",
    "print(tdo.date)\n",
    "print(tdo.minute)\n",
    "print(type(tdo.time()))\n",
    "# help(tdo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function strptime in module time:\n",
      "\n",
      "strptime(...)\n",
      "    strptime(string, format) -> struct_time\n",
      "    \n",
      "    Parse a string to a time tuple according to a format specification.\n",
      "    See the library reference manual for formatting codes (same as\n",
      "    strftime()).\n",
      "    \n",
      "    Commonly used format codes:\n",
      "    \n",
      "    %Y  Year with century as a decimal number.\n",
      "    %m  Month as a decimal number [01,12].\n",
      "    %d  Day of the month as a decimal number [01,31].\n",
      "    %H  Hour (24-hour clock) as a decimal number [00,23].\n",
      "    %M  Minute as a decimal number [00,59].\n",
      "    %S  Second as a decimal number [00,61].\n",
      "    %z  Time zone offset from UTC.\n",
      "    %a  Locale's abbreviated weekday name.\n",
      "    %A  Locale's full weekday name.\n",
      "    %b  Locale's abbreviated month name.\n",
      "    %B  Locale's full month name.\n",
      "    %c  Locale's appropriate date and time representation.\n",
      "    %I  Hour (12-hour clock) as a decimal number [01,12].\n",
      "    %p  Locale's equivalent of either AM or PM.\n",
      "    \n",
      "    Other codes may be available on your platform.  See documentation for\n",
      "    the C library strftime function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "help(time.strptime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversion: Using Lambda to apply a function inside a loop.\n",
    "\n",
    "\"Lambda\" is a tricky but highly useful command, especially when paired with \"map\". Map will apply a function to each element of a series, lambda will allow us to use each element in a function. It is more clear with an example. We can employ regular expressions in this way to clean up our search strings. \n",
    "\n",
    "The general syntax is: \n",
    "\n",
    "~~~\n",
    "SERIES = OLD_SERIES.map(lambda CELL: Some_Function(CELL)) \n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           [@JamesLuchte]\n",
       "1        [@BrynKewley, @nick_clegg, @EdwardDaveyMP, @Li...\n",
       "2                                          [@johnestevens]\n",
       "3                             [@edballsmp, @annesnelgrove]\n",
       "4                                                       []\n",
       "5                                                       []\n",
       "6           [@jpapworth, @sidmouthherald, @EDevonAlliance]\n",
       "7                                         [@Conservatives]\n",
       "8                                               [@YouTube]\n",
       "9                                          [@An_Phoblacht]\n",
       "10                                         [@discovery77_]\n",
       "11                                                      []\n",
       "12                                              [@ambermb]\n",
       "13                                                      []\n",
       "14       [@Nat_Worst, @Nigel_Pickover, @thedeniseb, @BB...\n",
       "15                        [@grahamemorris, @LouiseBaldock]\n",
       "16                                       [@Markfergusonuk]\n",
       "17             [@HercoRick, @LizMcInnesMP, @bluenose_carl]\n",
       "18                                 [@simpol_uk, @DanGreef]\n",
       "19                                           [@eddireader]\n",
       "20                                                      []\n",
       "21                                                      []\n",
       "22                                              [@LibDems]\n",
       "23                                                      []\n",
       "24       [@KiltedKipper, @DavidCoburnUKip, @Casumptious...\n",
       "25                                                      []\n",
       "26                                                      []\n",
       "27       [@StudentsReact, @GreenJillian, @TheGreenParty...\n",
       "28                                                      []\n",
       "29       [@Y_Influencers, @Buchan4SDown, @ChrisHazzardS...\n",
       "                               ...                        \n",
       "60038                                           [@LibDems]\n",
       "60039                      [@mick_doherty1, @PatDohertyMP]\n",
       "60040                                 [@UKIP_Daily, @UKIP]\n",
       "60041                                    [@taliskimberley]\n",
       "60042                                                   []\n",
       "60043                                                   []\n",
       "60044                                       [@mrchrisjohn]\n",
       "60045                                         [@CCHQPress]\n",
       "60046                          [@guyfburnett, @AJABurnett]\n",
       "60047                                         [@Vote_UKIP]\n",
       "60048                          [@Tawnynoran, @gildernewmp]\n",
       "60049                      [@Tighnacoille, @TiernanDouieb]\n",
       "60050                       [@LangtonSean, @freshbusiness]\n",
       "60051    [@herefordlibdems, @LibDems, @LibDemLords, @li...\n",
       "60052                           [@Hitchhiker105, @LibDems]\n",
       "60053            [@Seeds_Devon, @Radio_Exe, @ExeterRising]\n",
       "60054                                                   []\n",
       "60055                     [@nick_sutton22, @JoelforExeter]\n",
       "60056                                                   []\n",
       "60057                                          [@waggers5]\n",
       "60058                                                   []\n",
       "60059                                                   []\n",
       "60060                                                   []\n",
       "60061                                     [@DafyddTrystan]\n",
       "60062                                                   []\n",
       "60063                                          [@gtomkins]\n",
       "60064                                                   []\n",
       "60065                                                   []\n",
       "60066                                                   []\n",
       "60067    [@georgecista, @McPalace, @Ukip4Eddisbury, @ia...\n",
       "Name: mentionlist, Length: 60068, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lambda functions are useful in all sorts of ways. \n",
    "# For example, we could create a list of all the instances of @ mentions\n",
    "import re \n",
    "\n",
    "rMention = re.compile(\"@\\w+\")\n",
    "\n",
    "df[\"mentionlist\"] = df[\"text\"].map(lambda sasdfasdf: rMention.findall(sasdfasdf))\n",
    "\n",
    "# for c,cell in enumerate(df[\"text\"]):\n",
    "#     df.loc[c,\"mentionlist2\"] = rMention.findall(cell)\n",
    "\n",
    "display(df[\"mentionlist\"])\n",
    "# display(df[\"mentionlist2\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3], [5, 7], [8, 10, 20]] \n",
      " 0              []\n",
      "1             [9]\n",
      "2    [10, 12, 22]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "list1 = [[1,3],[5,7],[8,10,20]]\n",
    "series1 = pd.Series(list1)\n",
    "list2 = series1.map(lambda num: [process(username) for usernames in num])\n",
    "\n",
    "print(list1,\"\\n\",list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19] [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n"
     ]
    }
   ],
   "source": [
    "rr = list(range(0,20))\n",
    "rr2 = list(range(20,40))\n",
    "\n",
    "print(rr,rr2)\n",
    "for c,i in enumerate(rr):\n",
    "    print(c,rr[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also notice that I have now placed a list INSIDE a series. Indeed, a series can take all kinds of objects. What might we want to do with that series? Well, if we go by tweet we might want to check the distribution of number of @mentions in the tweets. This would require a second lambda. See for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    60068\n",
      "1    60068\n",
      "2    60068\n",
      "3    60068\n",
      "4    60068\n",
      "Name: mentionnum, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    4\n",
       "2    1\n",
       "3    2\n",
       "4    0\n",
       "Name: mentionnum, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     25413\n",
       "2     13276\n",
       "0     11610\n",
       "3      5286\n",
       "4      2201\n",
       "5      1062\n",
       "6       631\n",
       "7       269\n",
       "8       168\n",
       "9       115\n",
       "10       28\n",
       "11        9\n",
       "Name: mentionnum, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"mentionnum\"] = len(df[\"mentionlist\"])\n",
    "print(df[\"mentionnum\"].head())\n",
    "print()\n",
    "# Notice that len was the length of the entire series, not the per-row length. \n",
    "\n",
    "df[\"mentionnum\"] = df[\"mentionlist\"].map(lambda x: len(x))\n",
    "display(df[\"mentionnum\"].head())\n",
    "print()\n",
    "df[\"mentionnum\"].value_counts()\n",
    "\n",
    "# Recall in week one we used a mapper to clean some data. We mapped x based on a dictionary value. \n",
    "# Here we are using lambda to create an 'ad hoc' function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f08e780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"mentionnum\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8320     RT @foylejobs: @NIIRTA RT @Legenderryhour @dcsdcouncil @CoDerryAirport @Derry_Chamber @FoyleSDLP @DerrySinnFein @Derryvisitor @Gary_Middleton @ICE_NIreland    \n",
       "16869    RT @MargaretPinder: @DianaJohnsonMP @DrAyshaRaza @OnnMel @jackycrawford @Debbie_abrahams @YvetteCooperMP @Mary4Wakefield @stellacreasy @JoBrand_ @ThurrockPolly\n",
       "22932    RT @n10hairbear: Vote @UKLabour @CatherineWest1 @sarahsackman @olivercoppard @MGreenwoodWW @willscobie @coyleneil @WillJMartindale @joanryanEnfield @RupaHuq   \n",
       "24727    RT @n10hairbear: Vote @UKLabour @CatherineWest1 @sarahsackman @olivercoppard @MGreenwoodWW @willscobie @coyleneil @WillJMartindale @joanryanEnfield @RupaHuq   \n",
       "33051    RT @MedMarijuanaUK: @MedMarijuanaUK @BipLing @Caradelevingne @Clarkfrenchuk @BJGoldsmith `@sensibubble  @ZacGoldsmith @MedMarLegal @lilyallen @AlfieAllen      \n",
       "35216    RT @jamiewisemansnj: @stroud_neil @SLunnon1 @DavidEDrew @CasAnnStephens @richwi1son @MyStroudMP @StroudTV @StroudGreens @stroudconservat @StroudLabour         \n",
       "41511    RT @CroPage: N'Milo! @james4suffolk @BenAGulliford @mrs_sandbach @FxLibDems @ETA29 @pauljackmangrah @seamuski @AAndrewTurner @mower4distance @hwhawksley       \n",
       "51642    RT @a_cuthbert: And @MatthewRDavis85 @michelledonelan @JTomlinsonMP @RobertBuckland @Sk19791304 @wilcolyneham @Homesteadx10 @JerryWickham @A9_SLU @AshlezOn    \n",
       "55877    RT @MargaretPinder: @DianaJohnsonMP @DrAyshaRaza @OnnMel @jackycrawford @Debbie_abrahams @YvetteCooperMP @Mary4Wakefield @stellacreasy @JoBrand_ @ThurrockPolly\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8320     RT @foylejobs: @NIIRTA RT @Legenderr...\n",
       "16869    RT @MargaretPinder: @DianaJohnsonMP ...\n",
       "22932    RT @n10hairbear: Vote @UKLabour @Cat...\n",
       "24727    RT @n10hairbear: Vote @UKLabour @Cat...\n",
       "33051    RT @MedMarijuanaUK: @MedMarijuanaUK ...\n",
       "35216    RT @jamiewisemansnj: @stroud_neil @S...\n",
       "41511    RT @CroPage: N'Milo! @james4suffolk ...\n",
       "51642    RT @a_cuthbert: And @MatthewRDavis85...\n",
       "55877    RT @MargaretPinder: @DianaJohnsonMP ...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\",-1)\n",
    "display(df[df[\"mentionnum\"] == 11][\"text\"])\n",
    "\n",
    "print()\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\",40)\n",
    "display(df[df[\"mentionnum\"] == 11][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2015-05-05 07:05:44\n",
      "1   2015-05-05 13:16:07\n",
      "2   2015-05-05 22:11:10\n",
      "3   2015-05-05 16:00:51\n",
      "4   2015-05-05 22:03:30\n",
      "Name: datetime, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Now let's apply this to the date column\n",
    "\n",
    "df[\"datetime\"] = df[\"date\"].map(lambda entry: datetime.strptime(entry, '%Y-%m-%d %H:%M:%S.%f'))\n",
    "print(df[\"datetime\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-06 22:59:58\n",
      "<class 'pandas._libs.tslib.Timestamp'>\n",
      "<class 'pandas._libs.tslib.Timedelta'>\n",
      "1 days 22:59:51\n"
     ]
    }
   ],
   "source": [
    "# With the columns formatted as timestamps we can now query them as such. \n",
    "# We can get the min (i.e. earliest) or the max(i.e. latest) or the time delta, \n",
    "# which is the difference between two time periods\n",
    "\n",
    "maxtime = max(df[\"datetime\"])\n",
    "mintime = min(df[\"datetime\"])\n",
    "print(maxtime)\n",
    "print(type(mintime))\n",
    "print(type(maxtime - mintime))\n",
    "print(maxtime - mintime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Excel documents \n",
    "\n",
    "As you will discover, exporting to CSV from excel will not always work as planned. PANDAS has features to read from excel directly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Series Code</th>\n",
       "      <th>2013 [YR2013]</th>\n",
       "      <th>2014 [YR2014]</th>\n",
       "      <th>2015 [YR2015]</th>\n",
       "      <th>2016 [YR2016]</th>\n",
       "      <th>2017 [YR2017]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Access to electricity (% of population)</td>\n",
       "      <td>EG.ELC.ACCS.ZS</td>\n",
       "      <td>75.1544</td>\n",
       "      <td>89.5</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Access to electricity, rural (% of r...</td>\n",
       "      <td>EG.ELC.ACCS.RU.ZS</td>\n",
       "      <td>70.1294</td>\n",
       "      <td>87.8</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Access to electricity, urban (% of u...</td>\n",
       "      <td>EG.ELC.ACCS.UR.ZS</td>\n",
       "      <td>89.5526</td>\n",
       "      <td>98.7</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Adolescent fertility rate (births pe...</td>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>82.2638</td>\n",
       "      <td>76.7336</td>\n",
       "      <td>71.2034</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Adults (ages 15+) newly infected wit...</td>\n",
       "      <td>SH.HIV.INCD</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code                              Series Name  \\\n",
       "0  Afghanistan          AFG  Access to electricity (% of population)   \n",
       "1  Afghanistan          AFG  Access to electricity, rural (% of r...   \n",
       "2  Afghanistan          AFG  Access to electricity, urban (% of u...   \n",
       "3  Afghanistan          AFG  Adolescent fertility rate (births pe...   \n",
       "4  Afghanistan          AFG  Adults (ages 15+) newly infected wit...   \n",
       "\n",
       "         Series Code 2013 [YR2013] 2014 [YR2014] 2015 [YR2015] 2016 [YR2016]  \\\n",
       "0     EG.ELC.ACCS.ZS       75.1544          89.5            ..            ..   \n",
       "1  EG.ELC.ACCS.RU.ZS       70.1294          87.8            ..            ..   \n",
       "2  EG.ELC.ACCS.UR.ZS       89.5526          98.7            ..            ..   \n",
       "3        SP.ADO.TFRT       82.2638       76.7336       71.2034            ..   \n",
       "4        SH.HIV.INCD          1000          1000          1000          1000   \n",
       "\n",
       "  2017 [YR2017]  \n",
       "0            ..  \n",
       "1            ..  \n",
       "2            ..  \n",
       "3            ..  \n",
       "4            ..  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oops\n"
     ]
    }
   ],
   "source": [
    "dfGlobal = pd.read_excel(\"world_bank_country_data.xlsx\") # note this may not work on your computer.\n",
    "\n",
    "display(dfGlobal.head())\n",
    "\n",
    "print(\"oops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing R in Jupyter\n",
    "===\n",
    "\n",
    "Untested on windows, but on mac it is really easy (source: https://irkernel.github.io/installation/ ): \n",
    "1. Open an R shell in the terminal. \n",
    "2. Paste this command: \n",
    "~~~ r\n",
    "install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ', 'devtools', 'uuid', 'digest'))\n",
    "~~~\n",
    "3. Then this one\n",
    "~~~ r\n",
    "devtools::install_github('IRkernel/IRkernel')\n",
    "~~~\n",
    "4. Then this one\n",
    "~~~ r\n",
    "IRkernel::installspec()\n",
    "~~~\n",
    "\n",
    "Please note , this will not work from the R app or RStudio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The summative \n",
    "\n",
    "First, let's review the document that you were given. \n",
    "\n",
    "Now below, here is the guidance that I will give to the second marker. \n",
    "\n",
    "\n",
    "Guidance: \n",
    "As you will note, the students have been asked to write an essay based on a data merging task. This task should exemplify the data wrangling skills learned in class. To this end we are looking for figures, tables or findings that show evidence of the following:\n",
    "1. **Judiciousness with code**: Did the candidate check to make sure countries were merged correctly? How did the candidate address issues with missing data? Which year column(s) was chosen for the analysis and how was this determined. Has the candidate articulated the decisions that went into the final output clearly and exhaustively. Have they overcompensated by being didactic on a line-by-line level or more judicious by highlighting key decisions.\n",
    "2. **Proficiency with goals**: Looking at both the essay and the code in the appendix is it clear that the candidate understands concepts like abstraction. That is, are they using map, list comprehensions, and functions to create clear modular code or do they write a single long series of steps with for loops? Is the code commented and easy to follow?\n",
    "3. **Clarity of output**: Is the candidate able to express any relationships or descriptive statistics in a clear manner? Have they formatted their output in an academic form or are they pasting (or worse screenshotting) output directly from Jupyter? Are figures labelled clearly including labels on the x and y axis where appropriate. \n",
    "4. **Research questions and literature review**: This is not a substantive class and so the emphasis on questions of interest to social science are not of primary importane. However, the essay should still be internally coherent. Is the story being told about the data purposeful or ad hoc? Does the candidate articulate the research making reference to external literature? Overall, how does the candidate _frame_ the data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upcoming schedule\n",
    "- **End of class**: Feedback session with Victoria (Bernie leaves the room). Please consider being positive and constructive. To help anchor your assessment, last year most courses got between a 7 and and 8.5, it's ok to give a 10 or 9 and much like your grades, less than 5 letting us know this course was seriously broken.  \n",
    "- **Monday**: Marks and exemplary answers for week 3 formative should be published. \n",
    "- **Tuesday**: Bernie's office hours from 3-5pm. A drop in for questions about the formative. All answers will be given public to the attendees of the surgery. The instructor will not provide specific code examples, but rather 'talk through' how to craft code or answer a question effectively. \n",
    "- **Thursday**: In the morning Sian will be available to answer some last minute questions. \n",
    "- **Friday, week 5, noon**: Summative report submitted to Examinations School.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potpourri\n",
    "Let's take the last few minutes of class to ask a variety of questions about data wrangling and specific tasks. I can cover a number of different topics or share data sets. As this is a review, you decide where we take this.\n",
    "\n",
    "Finally, best of luck on your summative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
