{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "week 2 scratch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON normalize as an example:\n",
    "\n",
    "import urllib, urllib.request\n",
    "from pandas.io.json import json_normalize\n",
    "import json \n",
    "\n",
    "# Here's an example snippet. \n",
    "# We are going to download from the aww subreddit, \n",
    "# then use json_normalize to stick it right in a DataFrame\n",
    "# 1.\n",
    "SUBREDDIT = \"aww\"\n",
    "URL = \"http://www.reddit.com/r/%s.json\" % SUBREDDIT\n",
    "\n",
    "# URL queries are preceded by a header. Your browser has a header, too. \n",
    "# Check: https://www.whatismybrowser.com/detect/what-http-headers-is-my-browser-sending\n",
    "# Part of that header is the \"user agent\" string. Mine is: \n",
    "# Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.89 Safari/537.36 OPR/49.0.2725.39\n",
    "# Reddit expects a string other than the python default. \n",
    "# You should alter it to be unique to you. \n",
    "# 1/0 # DELETE ME AFTER YOU'VE CHANGED THE HEADER\n",
    "# 2. \n",
    "req = urllib.request.Request( URL, headers={'User-Agent': 'OII SDS class 2018.1/Hogan'})\n",
    "\n",
    "# IF you make repeated queries to Reddit, you must pause between them for a minimum of three seconds. \n",
    "# This snippet (time.sleep(3)) will do that for you, you just have to \"import time\" \n",
    "# time.sleep(4)\n",
    "# 3. \n",
    "infile = urllib.request.urlopen(req)\n",
    "\n",
    "# Here THE_DATA is we read the result and decode it. \n",
    "# 4. \n",
    "# Note the replace is there because of a bug in PANDAS 0.23.0. \n",
    "# See: https://stackoverflow.com/questions/50645240/pandas-json-normalize-fails-with-null-values-in-json\n",
    "redditData = json.loads(infile.read().decode('utf8').replace(\"null\",'\"\"'))\n",
    "\n",
    "# We we just say take the JSON and make a table. \n",
    "# 5. \n",
    "rtable = json_normalize(redditData, errors='ignore')\n",
    "rtable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
